{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "作業檔案：\n",
    "- hw3.ipynb\n",
    "\n",
    "資料：\n",
    "https://www.sharecast.com/index/SP_500/prices/download\n",
    "\n",
    "- train.csv: S&P 500 訓練資料(2009-2017)\n",
    "- test.csv: S&P 500 測試資料(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "#Date  Open Price  Close Price  High Price  Low Price   Volume\n",
    "drop_col_names = ['Date'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "0      902.99       931.80      934.73     899.35  4048270080   \n",
      "1      929.17       927.45      936.63     919.53  5413910016   \n",
      "2      931.17       934.70      943.85     927.28  5392620032   \n",
      "3      927.45       906.65      927.45     902.37  4704940032   \n",
      "4      905.73       909.73      910.00     896.81  4991549952   \n",
      "\n",
      "   Tomorrow Movement  \n",
      "0                0.0  \n",
      "1                1.0  \n",
      "2                0.0  \n",
      "3                1.0  \n",
      "4                0.0  \n",
      "      Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "2259     2684.22      2683.34     2685.35    2678.13  1383888512   \n",
      "2260     2679.09      2680.50     2682.74    2677.96  1103808384   \n",
      "2261     2682.10      2682.62     2685.64    2678.91  1149108352   \n",
      "2262     2686.10      2687.54     2687.66    2682.69  1126089856   \n",
      "2263     2689.15      2673.61     2692.12    2673.61  1332374016   \n",
      "\n",
      "      Tomorrow Movement  \n",
      "2259                0.0  \n",
      "2260                1.0  \n",
      "2261                1.0  \n",
      "2262                0.0  \n",
      "2263                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with the previous days as the training target\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !--- You can add your own data preprocessing here ---!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(2263,)\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(251, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n",
      "(251,)\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "train_x_df = train_df.drop(columns=['Tomorrow Movement'])\n",
    "train_y_df = train_df['Tomorrow Movement']\n",
    "\n",
    "test_x_df = test_df.drop(columns=['Tomorrow Movement'])\n",
    "test_y_df = test_df['Tomorrow Movement']\n",
    "\n",
    "print(train_x_df.shape)\n",
    "print(train_x_df.head())\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())\n",
    "print('-----')\n",
    "print(test_x_df.shape)\n",
    "print(test_x_df.head())\n",
    "print(test_y_df.shape)\n",
    "print(test_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price    Volume\n",
      "0   -1.552572    -1.494607   -1.505683  -1.541181  0.813175\n",
      "1   -1.498571    -1.503581   -1.501760  -1.499581  1.823826\n",
      "2   -1.494446    -1.488625   -1.486853  -1.483605  1.808070\n",
      "3   -1.502119    -1.546489   -1.520714  -1.534956  1.299148\n",
      "4   -1.546921    -1.540136   -1.556744  -1.546417  1.511255\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "# !--- Modify here if you want ---!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_df)\n",
    "\n",
    "normalized_train_x_df = scaler.transform(train_x_df)\n",
    "normalized_train_x_df = np.transpose(normalized_train_x_df)\n",
    "\n",
    "normalized_train_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_train_x_df[0],\n",
    "    'Close Price': normalized_train_x_df[1],\n",
    "    'High Price': normalized_train_x_df[2],\n",
    "    'Low Price': normalized_train_x_df[3],\n",
    "    'Volume': normalized_train_x_df[4],\n",
    "})\n",
    "\n",
    "normalized_test_x_df = scaler.transform(test_x_df)\n",
    "normalized_test_x_df = np.transpose(normalized_test_x_df)\n",
    "normalized_test_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_test_x_df[0],\n",
    "    'Close Price': normalized_test_x_df[1],\n",
    "    'High Price': normalized_test_x_df[2],\n",
    "    'Low Price': normalized_test_x_df[3],\n",
    "    'Volume': normalized_test_x_df[4],\n",
    "})\n",
    "\n",
    "print(normalized_train_x_df.head())\n",
    "print(train_y_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5475033141847105\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict using Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model =LogisticRegression()  # !--- Initialize the model here ---!\n",
    "lr_model.fit(normalized_train_x_df,train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "#y_train_pred=lr_model.predict(normalized_train_x_df)\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "lr_training_acc =accuracy_score(train_y_df, lr_model.predict(normalized_train_x_df))\n",
    "print(lr_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "lr_predict_test_result = lr_model.predict(normalized_test_x_df)\n",
    "lr_testing_acc = accuracy_score(test_y_df, lr_predict_test_result)\n",
    "print(lr_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.5137282196515144, 0.5258964143426295, 0.3694764768608263, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(1, 118, 1, 131)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, lr_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, lr_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5483870967741935\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict with SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma='scale') # !--- Initialize the model here ---!\n",
    "svc_model.fit(normalized_train_x_df,train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "svc_training_acc = accuracy_score(train_y_df, svc_model.predict(normalized_train_x_df))\n",
    "print(svc_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "svc_predict_test_result = svc_model.predict(normalized_test_x_df)\n",
    "svc_testing_acc = accuracy_score(test_y_df, svc_predict_test_result)\n",
    "print(svc_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(svc_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.2765670386184346, 0.5258964143426295, 0.3624977895207681, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(0, 119, 0, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, svc_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, svc_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  0  1\n",
      "2  1  0\n",
      "3  0  1\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "# Define NN output groundtruth\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(train_y_df == 0, 1, 0)[:])\n",
    "train_y_df = pd.DataFrame(data=np.where(train_y_df == 0, 0, 1)[:])\n",
    "train_y_df = pd.concat( [ falling_prob, train_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(test_y_df == 0, 1, 0)[:])\n",
    "test_y_df = pd.DataFrame(data=np.where(test_y_df == 0, 0, 1)[:])\n",
    "test_y_df = pd.concat( [ falling_prob, test_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d1b9d9dc956f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_train_x_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_train_x_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# !-- Fill the training batch data here --!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# !-- Fill the prediction & groundtruth here to calculate loss --!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-d1b9d9dc956f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0macti_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[1;33m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \"\"\"\n\u001b[1;32m-> 1350\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# Define NN structure\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !--- You can modify the NN structure here ---!\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        acti_out = F.relu(h)\n",
    "        y_pred = self.linear2(h)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N = batch size, D_in = input size, H = hidden size, D_out = output size\n",
    "N, D_in, H, D_out = 300, 5, 100, 2  # !--- You can modify here ---!\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum') # !--- You can modify here ---!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # !--- You can modify here ---!\n",
    "\n",
    "\n",
    "# Train NN\n",
    "# !--- You can modify here ---!\n",
    "\n",
    "for t in range(1000):\n",
    "    for batch_num in range(N, len(normalized_train_x_df), N): \n",
    "        y_pred = model() # !-- Fill the training batch data here --!\n",
    "        loss = criterion() # !-- Fill the prediction & groundtruth here to calculate loss --!\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%100 == 0):\n",
    "        print('epoch:%d - loss:%.10f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "nn_predict_train_y =  # !-- Predict training data here --!\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(train_y_df[0], result_train))\n",
    "\n",
    "nn_predict_test_y =  # !-- Predict training data here --!\n",
    "result_test = np.where(nn_predict_test_y[:, 0] > nn_predict_test_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(test_y_df[0], result_test))\n",
    "\n",
    "print('\\npredicted testing prob:')\n",
    "print(nn_predict_test_y)\n",
    "print('\\npredicted testing labels:')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('\\nprecision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df[0], result_test, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df[0], result_test).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
